"""
For License information see the LICENSE file.

Authors: Michael Yonli

"""
from leaker.attack.arr.estimators import get_fingerprint, unseen, get_jackk_coeffs, jackknife_selftune
from numpy.random import beta
import numpy as np
import pytest
from math import log2 as log


def test_fingerprint():
    np.testing.assert_array_equal(get_fingerprint([0, 0, 0, 1]), [0, 1, 0, 1])
    np.testing.assert_array_equal(get_fingerprint([0, 1, 4, 3, 0, 0, 2, 4]), [0, 3, 1, 1])

    t_data0 = np.ceil(beta(1, 1, 500) * 20)
    t_data1 = np.ceil(beta(1, 3, 2000) * 500)

    fp0 = get_fingerprint(t_data0)
    assert sum([i * x for i, x in enumerate(fp0)]) == 500

    fp1 = get_fingerprint(t_data1)
    assert sum([i * x for i, x in enumerate(fp1)]) == 2000


# Takes about 3 seconds
@pytest.mark.skip()
def test_unseen():
    np.random.seed(1)
    # Testdata was generated by Matlab implementation
    # data = makeFinger(round(rand([100 1])*10))
    # 0 added to account for different makeFinger python impl
    data = [0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 1, 3, 0, 1, 0, 1]

    hist, p = unseen(data)
    prob_covered = sum([x * y for x, y in zip(hist, p)])

    assert abs(1 - prob_covered) < 1 * 10 ** 9

    support_size = sum(hist)

    # value comes from matlab version
    assert abs(support_size - 8.8642) < 1 * 10 ** -3

    # Data taken from KPT19 Fig6

    N = 10 ** 5

    data = np.round(beta(1, 2.5, N) * N)
    f = get_fingerprint(data)
    hist, _ = unseen(f)
    rerr = abs(N - sum(hist)) / N
    assert rerr < 0.15
    print(f"Test 1 relative error {rerr}")

    data = np.round(beta(1, 10, 10 * N) * N)
    f = get_fingerprint(data)
    hist, _ = unseen(f)
    rerr = abs(N - sum(hist)) / N
    assert rerr < 0.5
    print(f"Test 2 relative error {rerr}")


# Takes about 30 minutes
def test_unseen_valiant():
    """
    Test based on testing data as described in the paper describing the unseen estimator. This differs from the other
    test, which only considers testdata from KPT19.

    """
    np.random.seed(1)

    def unif(k, n):
        return np.random.random_integers(k, size=n), - k * (1 / k) * log(1 / k)

    def mixunif(k, n):
        return (
        np.random.choice(np.arange(1, k + 1), n, p=[5 / (2 * k) if i < k / 5 else 5 / (8 * k) for i in range(k)]),
        - (k / 5) * (5 / (2 * k)) * log(5 / (2 * k)) - (4 * k / 5) * (5 / (8 * k)) * log(5 / (8 * k)))

    def zipf(k, n):
        s = sum([1 / i for i in range(1, k + 1)])
        p = [(1 / (i + 1)) / s for i in range(k)]

        ent = sum(map(lambda x: -log(x) * x, p))

        return np.random.choice(np.arange(1, k + 1), n, p=p), ent

    def zipf2(k, n):
        s = sum([1 / i ** 0.6 for i in range(1, k + 1)])
        p = [(1 / (i + 1) ** 0.6) / s for i in range(k)]

        ent = sum(map(lambda x: -log(x) * x, p))

        return np.random.choice(np.arange(1, k + 1), n, p=p), ent

    def geom(k, n):
        # Not sure if this is correct or contains one by off error
        p = 1 / k
        ent = (- (1 - p) * log(1 - p) - p * log(p)) / p

        return np.random.geometric(p, n), ent

    def mixgeomzipf(k, n):
        # Not sure if this is how the authors mixed the distributions
        pgeom = [(1 / k) * (1 - 1 / k) ** i for i in range(k // 2)]

        s = sum(range((k + 1) // 2))
        pzipf = [1 / (i + 1) / s for i in range((k + 1) // 2)]

        pgeom.extend(pzipf)
        tprob = sum(pgeom)
        p = list(map(lambda x: x / tprob, pgeom))
        ent = sum(map(lambda x: -log(x) * x, p))

        return np.random.choice(np.arange(1, k + 1), n, p=p), ent

    k = 1000
    x0 = int(k ** 0.6)
    x1 = int(k ** 1.25)

    dist = [unif, mixunif, zipf, zipf2, geom, mixgeomzipf]

    for d in dist:
        print(f"Using distribution: {d.__name__}")
        for n in [x0, x1]:
            print(f"n = {n}")
            pred = []

            for _ in range(500):
                samples, entropy = d(k, n)
                fp = get_fingerprint(samples)

                hist, p = unseen(fp)
                e = sum(map(lambda x: - x[0] * x[1] * log(x[1]), zip(hist, p)))
                pred.append((e - entropy) ** 2)

            rmse = np.sqrt(np.mean(np.array(pred)))
            print(f"RMSE: {rmse}")

            if d == geom and n == int(k ** 0.6):
                assert rmse < 1.6
            elif n == int(k ** 1.25):
                assert rmse < 0.1
            else:
                assert rmse < 1


def test_jackk_coeffs():
    f = [0, 1, 2, 3, 4, 0, 6, 7, 8, 9, 10, 300, 30298, 10000000]
    d = sum(f)
    m = len(f) - 1

    coeffs = get_jackk_coeffs(f, m)

    j1 = coeffs[0]
    j2 = coeffs[1]
    j3 = coeffs[2]
    j4 = coeffs[3]

    # formulas come from paper
    assert j1[0] == pytest.approx(d)
    assert j2[0] == pytest.approx(d)
    assert j3[0] == pytest.approx(d)
    assert j4[0] == pytest.approx(d)

    assert j1[1] == pytest.approx((m - 1) / m)
    assert j2[1] == pytest.approx((2 * m - 3) / m)
    assert j3[1] == pytest.approx((3 * m - 6) / m)
    assert j4[1] == pytest.approx((4 * m - 10) / m)

    assert j1[2] == pytest.approx(0)
    assert j2[2] == pytest.approx(-(m - 2) ** 2 / (m * (m - 1)))
    assert j3[2] == pytest.approx(-(3 * m ** 2 - 15 * m + 19) / ((m - 1) * m))
    assert j4[2] == pytest.approx(-(6 * m ** 2 - 36 * m + 55) / ((m - 1) * m))

    assert j1[3] == pytest.approx(0)
    assert j2[3] == pytest.approx(0)
    assert j3[3] == pytest.approx((m - 3) ** 3 / ((m - 2) * (m - 1) * m))
    assert j4[3] == pytest.approx((4 * m ** 3 - 42 * m ** 2 + 148 * m - 175) / (m * (m - 1) * (m - 2)))

    assert j1[4] == j2[4] == j3[4] == pytest.approx(0)
    assert j4[4] == pytest.approx(-(m - 4) ** 4 / ((m - 3) * (m - 2) * (m - 1) * m))


def test_jackk():
    np.random.seed(1)
    N = 10 ** 5

    data = np.round(beta(1, 2.5, 5 * 10 ** 4) * N)
    f = get_fingerprint(data)
    d = jackknife_selftune(f, N)
    r_err = abs((d - N) / N)
    assert r_err < 0.10
    print(f"Jack T1 RERR: {r_err}")

    data = np.round(beta(1, 17, 5 * 10 ** 4) * N)
    f = get_fingerprint(data)
    d = jackknife_selftune(f, N)
    r_err = abs((d - N) / N)
    assert r_err < 0.75
    print(f"Jack T2 RERR: {r_err}")


def test_jackknife_burnham():
    # Test uses data from burnham 1979
    fp = [0, 43, 16, 8, 6, 0, 2, 1]
    d = jackknife_selftune(fp, 18)

    assert abs(d - 158) < 1


def test_jackcrash():
    np.random.seed(1)
    data = [73050, 98048, 95043, 90051, 79044, 75051, 75052, 87053, 76050, 85050, 72050, 95043, 80045, 92053,
            95045, 76050, 75051, 84042, 83053, 77053, 88046, 77051, 95046, 95043, 74046, 75051, 83044, 78053,
            75049, 84046, 80043, 77050, 83042, 91042]
    f = get_fingerprint(data)
    d = jackknife_selftune(f, len(data))
    assert d is not None
